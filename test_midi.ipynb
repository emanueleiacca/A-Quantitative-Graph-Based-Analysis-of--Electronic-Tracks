{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretty_midi networkx numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from math import log\n",
    "\n",
    "midi_path = \"beethoven_fr_elise_piano_version.mid\"\n",
    "pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "\n",
    "# Collect (start_time, pitch) for all NON-drum instruments\n",
    "events = []\n",
    "for inst in pm.instruments:\n",
    "    if inst.is_drum:\n",
    "        continue\n",
    "    for note in inst.notes:\n",
    "        events.append((note.start, note.pitch))\n",
    "\n",
    "# Sort by time\n",
    "events.sort(key=lambda x: x[0])\n",
    "\n",
    "# Group by onset (within small tolerance to handle float noise)\n",
    "TIME_TOL = 1e-3\n",
    "time_slices = []  # list of sets of pitches\n",
    "current_time = None\n",
    "current_chord = []\n",
    "\n",
    "for t, p in events:\n",
    "    if current_time is None:\n",
    "        current_time = t\n",
    "        current_chord = [p]\n",
    "    elif abs(t - current_time) <= TIME_TOL:\n",
    "        current_chord.append(p)\n",
    "    else:\n",
    "        time_slices.append(sorted(set(current_chord)))\n",
    "        current_time = t\n",
    "        current_chord = [p]\n",
    "\n",
    "if current_chord:\n",
    "    time_slices.append(sorted(set(current_chord)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a33c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build directed weighted edges\n",
    "edge_weights = Counter()\n",
    "nodes = set()\n",
    "\n",
    "for chord_a, chord_b in zip(time_slices[:-1], time_slices[1:]):\n",
    "    for i in chord_a:\n",
    "        for j in chord_b:\n",
    "            if i == j:\n",
    "                continue  # remove self-loops right away\n",
    "            edge_weights[(i, j)] += 1\n",
    "            nodes.add(i)\n",
    "            nodes.add(j)\n",
    "\n",
    "# Create a NetworkX DiGraph\n",
    "G = nx.DiGraph()\n",
    "for (u, v), w in edge_weights.items():\n",
    "    G.add_edge(u, v, weight=w)\n",
    "\n",
    "# In case any isolated nodes appear (unlikely here)\n",
    "for n in nodes:\n",
    "    if n not in G:\n",
    "        G.add_node(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6344181",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "density = nx.density(G)\n",
    "\n",
    "print(\"Vertices (notes):\", n)\n",
    "print(\"Edges:\", m)\n",
    "print(\"Density:\", density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc16e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_reciprocity(G):\n",
    "    W = 0.0\n",
    "    W_bidir = 0.0\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        w_uv = data[\"weight\"]\n",
    "        W += w_uv\n",
    "        if G.has_edge(v, u):\n",
    "            w_vu = G[v][u][\"weight\"]\n",
    "            W_bidir += min(w_uv, w_vu)\n",
    "    if W == 0:\n",
    "        return 0.0\n",
    "    return W_bidir / W\n",
    "\n",
    "r_real = weighted_reciprocity(G)\n",
    "\n",
    "import random\n",
    "\n",
    "def shuffle_outgoing_weights_preserve_strength(G):\n",
    "    H = G.copy()\n",
    "    for u in H.nodes():\n",
    "        out_edges = list(H.out_edges(u, data=True))\n",
    "        if len(out_edges) <= 1:\n",
    "            continue\n",
    "        weights = [d[\"weight\"] for _, _, d in out_edges]\n",
    "        random.shuffle(weights)\n",
    "        for (idx, (src, dst, data)) in enumerate(out_edges):\n",
    "            data[\"weight\"] = weights[idx]\n",
    "    return H\n",
    "\n",
    "H_null = shuffle_outgoing_weights_preserve_strength(G)\n",
    "r_null = weighted_reciprocity(H_null)\n",
    "\n",
    "rho_w = (r_real - r_null) / (1 - r_null) if r_null != 1 else 0.0\n",
    "\n",
    "print(\"Weighted reciprocity r_real:\", r_real)\n",
    "print(\"Weighted reciprocity r_null:\", r_null)\n",
    "print(\"Weighted reciprocity rho_w:\", rho_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_entropy(G, u):\n",
    "    out_edges = list(G.out_edges(u, data=True))\n",
    "    k = len(out_edges)\n",
    "    if k <= 1:\n",
    "        return 0.0\n",
    "    weights = np.array([d[\"weight\"] for _, _, d in out_edges], dtype=float)\n",
    "    p = weights / weights.sum()\n",
    "    H = -np.sum(p * np.log(p))\n",
    "    H_max = np.log(k)\n",
    "    return H / H_max if H_max > 0 else 0.0\n",
    "\n",
    "entropies = [node_entropy(G, u) for u in G.nodes()]\n",
    "mean_entropy = np.mean(entropies)\n",
    "\n",
    "print(\"Mean node entropy:\", mean_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_efficiency_unweighted(G):\n",
    "    # Shortest path lengths by hop count\n",
    "    sp = dict(nx.all_pairs_shortest_path_length(G))\n",
    "    nodes = list(G.nodes())\n",
    "    n = len(nodes)\n",
    "    s = 0.0\n",
    "    count = 0\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            if i == j:\n",
    "                continue\n",
    "            d = sp.get(i, {}).get(j, np.inf)\n",
    "            if np.isfinite(d) and d > 0:\n",
    "                s += 1.0 / d\n",
    "                count += 1\n",
    "    return s / count if count > 0 else 0.0\n",
    "\n",
    "def global_efficiency_weighted(G):\n",
    "    H = G.copy()\n",
    "    for u, v, data in H.edges(data=True):\n",
    "        # cost = 1 / w, and we only assumed w>=1\n",
    "        data[\"cost\"] = 1.0 / data[\"weight\"]\n",
    "    # Use Dijkstra on 'cost'\n",
    "    sp = dict(nx.all_pairs_dijkstra_path_length(H, weight=\"cost\"))\n",
    "    nodes = list(H.nodes())\n",
    "    n = len(nodes)\n",
    "    s = 0.0\n",
    "    count = 0\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            if i == j:\n",
    "                continue\n",
    "            d = sp.get(i, {}).get(j, np.inf)\n",
    "            if np.isfinite(d) and d > 0:\n",
    "                s += 1.0 / d\n",
    "                count += 1\n",
    "    return s / count if count > 0 else 0.0\n",
    "\n",
    "E_unweighted = global_efficiency_unweighted(G)\n",
    "E_weighted   = global_efficiency_weighted(G)\n",
    "\n",
    "print(\"Unweighted efficiency:\", E_unweighted)\n",
    "print(\"Weighted efficiency:\", E_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_counts = np.zeros(12, dtype=float)\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    # Count each transition as many times as its weight\n",
    "    w = data[\"weight\"]\n",
    "    interval = (v - u) % 12\n",
    "    interval_counts[interval] += w\n",
    "\n",
    "# L2 normalize\n",
    "norm = np.linalg.norm(interval_counts)\n",
    "if norm > 0:\n",
    "    interval_vec = interval_counts / norm\n",
    "else:\n",
    "    interval_vec = interval_counts\n",
    "\n",
    "interval_names = [\n",
    "    \"unison\", \"m2\", \"M2\", \"m3\", \"M3\", \"P4\", \"TT\", \"P5\",\n",
    "    \"m6\", \"M6\", \"m7\", \"M7\"\n",
    "]\n",
    "\n",
    "print(\"Interval embedding (L2 normalized):\")\n",
    "for name, val in zip(interval_names, interval_vec):\n",
    "    print(f\"{name}: {val:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
