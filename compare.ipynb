{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172c449d",
   "metadata": {},
   "source": [
    "Imports & basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2fb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports & config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pretty_midi\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Audio config (aligned with your code)\n",
    "SR = 44100\n",
    "FRAME_LENGTH = 1024\n",
    "HOP_LENGTH = 512\n",
    "EPS = 1e-10\n",
    "\n",
    "# Paths\n",
    "MIDI_PATH = \"beethoven_fr_elise_piano_version.mid\"\n",
    "AUDIO_PATH = \"beethoven_fr_elise_piano_version.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb861e23",
   "metadata": {},
   "source": [
    "MIDI → pitch-class chord sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cdd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: MIDI utilities\n",
    "\n",
    "def midi_chord_sequence_pitchclass(midi_path, time_tol=1e-3):\n",
    "    \"\"\"\n",
    "    From MIDI -> sequence of chords in pitch-class space (0..11).\n",
    "    Each chord is a tuple of pitch classes; consecutive duplicates merged.\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "    events = []\n",
    "\n",
    "    # Collect (start_time, pitch) from non-drum instruments\n",
    "    for inst in pm.instruments:\n",
    "        if inst.is_drum:\n",
    "            continue\n",
    "        for note in inst.notes:\n",
    "            events.append((note.start, note.pitch))\n",
    "\n",
    "    if not events:\n",
    "        return []\n",
    "\n",
    "    events.sort(key=lambda x: x[0])\n",
    "\n",
    "    time_slices = []\n",
    "    current_time = None\n",
    "    current_chord = []\n",
    "\n",
    "    for t, p in events:\n",
    "        if current_time is None:\n",
    "            current_time = t\n",
    "            current_chord = [p]\n",
    "        elif abs(t - current_time) <= time_tol:\n",
    "            current_chord.append(p)\n",
    "        else:\n",
    "            # close previous slice\n",
    "            pcs = sorted({note % 12 for note in current_chord})\n",
    "            time_slices.append(tuple(pcs))\n",
    "            current_time = t\n",
    "            current_chord = [p]\n",
    "\n",
    "    if current_chord:\n",
    "        pcs = sorted({note % 12 for note in current_chord})\n",
    "        time_slices.append(tuple(pcs))\n",
    "\n",
    "    # compress consecutive duplicate chords\n",
    "    chords = []\n",
    "    prev = None\n",
    "    for c in time_slices:\n",
    "        if c != prev and len(c) > 0:\n",
    "            chords.append(c)\n",
    "            prev = c\n",
    "\n",
    "    return chords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f49ab",
   "metadata": {},
   "source": [
    "Audio → chroma chord sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: audio / chroma utilities\n",
    "\n",
    "CHROMA_THRESH = 0.3  # relative threshold within frame\n",
    "\n",
    "def chroma_chord_sequence(y, sr=SR, hop_length=HOP_LENGTH, thresh=CHROMA_THRESH):\n",
    "    \"\"\"\n",
    "    From audio -> chroma -> sequence of chords in pitch-class space (0..11).\n",
    "    Each chord is a tuple of pitch classes; consecutive duplicates merged.\n",
    "    \"\"\"\n",
    "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=hop_length)\n",
    "    T = chroma.shape[1]\n",
    "\n",
    "    chords = []\n",
    "    prev_chord = None\n",
    "\n",
    "    for t in range(T):\n",
    "        frame = chroma[:, t]\n",
    "        if frame.max() < 1e-6:\n",
    "            active = ()\n",
    "        else:\n",
    "            act = np.where(frame >= thresh * frame.max())[0]\n",
    "            active = tuple(sorted(set(act.tolist())))\n",
    "\n",
    "        if active != prev_chord and len(active) > 0:\n",
    "            chords.append(active)\n",
    "            prev_chord = active\n",
    "\n",
    "    return chords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0e4e8",
   "metadata": {},
   "source": [
    "Build graph from chord sequence (shared for MIDI & audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: chord seq -> graph + metrics\n",
    "\n",
    "def build_chord_transition_graph(chords):\n",
    "    \"\"\"\n",
    "    chords: list of tuples of pitch classes (0..11)\n",
    "    Returns DiGraph with edges weighted by transition counts.\n",
    "    No self-loops.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for chord_a, chord_b in zip(chords[:-1], chords[1:]):\n",
    "        for i in chord_a:\n",
    "            for j in chord_b:\n",
    "                if i == j:\n",
    "                    continue  # no self-loops\n",
    "                if G.has_edge(i, j):\n",
    "                    G[i][j][\"weight\"] += 1\n",
    "                else:\n",
    "                    G.add_edge(i, j, weight=1)\n",
    "    return G\n",
    "\n",
    "\n",
    "def weighted_reciprocity(G):\n",
    "    W = 0.0\n",
    "    W_bidir = 0.0\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        w_uv = data[\"weight\"]\n",
    "        W += w_uv\n",
    "        if G.has_edge(v, u):\n",
    "            w_vu = G[v][u][\"weight\"]\n",
    "            W_bidir += min(w_uv, w_vu)\n",
    "    if W == 0:\n",
    "        return 0.0\n",
    "    return W_bidir / W\n",
    "\n",
    "\n",
    "def shuffle_outgoing_weights_preserve_strength(G, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    H = G.copy()\n",
    "    for u in H.nodes():\n",
    "        out_edges = list(H.out_edges(u, data=True))\n",
    "        if len(out_edges) <= 1:\n",
    "            continue\n",
    "        weights = [d[\"weight\"] for _, _, d in out_edges]\n",
    "        rng.shuffle(weights)\n",
    "        for (idx, (src, dst, data)) in enumerate(out_edges):\n",
    "            data[\"weight\"] = float(weights[idx])\n",
    "    return H\n",
    "\n",
    "\n",
    "def normalized_weighted_reciprocity(G, n_null=20):\n",
    "    r_real = weighted_reciprocity(G)\n",
    "    if G.number_of_edges() == 0:\n",
    "        return r_real, 0.0, 0.0\n",
    "\n",
    "    r_null_vals = []\n",
    "    for _ in range(n_null):\n",
    "        H = shuffle_outgoing_weights_preserve_strength(G)\n",
    "        r_null_vals.append(weighted_reciprocity(H))\n",
    "\n",
    "    r_null = float(np.mean(r_null_vals))\n",
    "    if r_null >= 1.0:\n",
    "        rho = 0.0\n",
    "    else:\n",
    "        rho = (r_real - r_null) / (1 - r_null)\n",
    "    return r_real, r_null, rho\n",
    "\n",
    "\n",
    "def node_entropy(G, u):\n",
    "    out_edges = list(G.out_edges(u, data=True))\n",
    "    k = len(out_edges)\n",
    "    if k <= 1:\n",
    "        return 0.0\n",
    "    weights = np.array([d[\"weight\"] for _, _, d in out_edges], dtype=float)\n",
    "    p = weights / (weights.sum() + EPS)\n",
    "    H = -np.sum(p * np.log(p + EPS))\n",
    "    H_max = np.log(k + EPS)\n",
    "    return H / (H_max + EPS)\n",
    "\n",
    "\n",
    "def mean_node_entropy(G):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return 0.0\n",
    "    entropies = [node_entropy(G, u) for u in G.nodes()]\n",
    "    return float(np.mean(entropies))\n",
    "\n",
    "\n",
    "def global_efficiency_unweighted(G):\n",
    "    if G.number_of_nodes() <= 1:\n",
    "        return 0.0\n",
    "    sp = dict(nx.all_pairs_shortest_path_length(G))\n",
    "    nodes = list(G.nodes())\n",
    "    s = 0.0\n",
    "    count = 0\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            if i == j:\n",
    "                continue\n",
    "            d = sp.get(i, {}).get(j, np.inf)\n",
    "            if np.isfinite(d) and d > 0:\n",
    "                s += 1.0 / d\n",
    "                count += 1\n",
    "    return float(s / count) if count > 0 else 0.0\n",
    "\n",
    "\n",
    "def global_efficiency_weighted(G):\n",
    "    if G.number_of_nodes() <= 1:\n",
    "        return 0.0\n",
    "    H = G.copy()\n",
    "    for u, v, data in H.edges(data=True):\n",
    "        data[\"cost\"] = 1.0 / float(data[\"weight\"])\n",
    "\n",
    "    sp = dict(nx.all_pairs_dijkstra_path_length(H, weight=\"cost\"))\n",
    "    nodes = list(H.nodes())\n",
    "    s = 0.0\n",
    "    count = 0\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            if i == j:\n",
    "                continue\n",
    "            d = sp.get(i, {}).get(j, np.inf)\n",
    "            if np.isfinite(d) and d > 0:\n",
    "                s += 1.0 / d\n",
    "                count += 1\n",
    "    return float(s / count) if count > 0 else 0.0\n",
    "\n",
    "\n",
    "def interval_embedding_12d(G):\n",
    "    \"\"\"\n",
    "    12D interval profile over pitch classes; L2-normalized.\n",
    "    \"\"\"\n",
    "    counts = np.zeros(12, dtype=float)\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        w = float(data[\"weight\"])\n",
    "        interval = (v - u) % 12\n",
    "        counts[interval] += w\n",
    "    norm = np.linalg.norm(counts)\n",
    "    if norm > 0:\n",
    "        return counts / norm\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b556c1",
   "metadata": {},
   "source": [
    "Convenience wrappers for “MIDI network” and “audio network”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa858a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: compute metrics for MIDI vs audio\n",
    "\n",
    "def compute_midi_network_metrics(midi_path):\n",
    "    chords = midi_chord_sequence_pitchclass(midi_path)\n",
    "    G = build_chord_transition_graph(chords)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[\"n_nodes\"] = G.number_of_nodes()\n",
    "    metrics[\"n_edges\"] = G.number_of_edges()\n",
    "    metrics[\"density\"] = nx.density(G)\n",
    "\n",
    "    r_real, r_null, rho = normalized_weighted_reciprocity(G)\n",
    "    metrics[\"r_real\"] = r_real\n",
    "    metrics[\"r_null\"] = r_null\n",
    "    metrics[\"rho_norm\"] = rho\n",
    "\n",
    "    metrics[\"mean_entropy\"] = mean_node_entropy(G)\n",
    "    metrics[\"eff_unweighted\"] = global_efficiency_unweighted(G)\n",
    "    metrics[\"eff_weighted\"] = global_efficiency_weighted(G)\n",
    "\n",
    "    metrics[\"interval_vec\"] = interval_embedding_12d(G)\n",
    "    metrics[\"graph\"] = G\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_audio_network_metrics(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=SR, mono=True)\n",
    "    chords = chroma_chord_sequence(y, sr=sr, hop_length=HOP_LENGTH)\n",
    "    G = build_chord_transition_graph(chords)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[\"n_nodes\"] = G.number_of_nodes()\n",
    "    metrics[\"n_edges\"] = G.number_of_edges()\n",
    "    metrics[\"density\"] = nx.density(G)\n",
    "\n",
    "    r_real, r_null, rho = normalized_weighted_reciprocity(G)\n",
    "    metrics[\"r_real\"] = r_real\n",
    "    metrics[\"r_null\"] = r_null\n",
    "    metrics[\"rho_norm\"] = rho\n",
    "\n",
    "    metrics[\"mean_entropy\"] = mean_node_entropy(G)\n",
    "    metrics[\"eff_unweighted\"] = global_efficiency_unweighted(G)\n",
    "    metrics[\"eff_weighted\"] = global_efficiency_weighted(G)\n",
    "\n",
    "    metrics[\"interval_vec\"] = interval_embedding_12d(G)\n",
    "    metrics[\"graph\"] = G\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03f54d",
   "metadata": {},
   "source": [
    "Run for Für Elise and create comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: run everything for Für Elise\n",
    "\n",
    "midi_metrics = compute_midi_network_metrics(MIDI_PATH)\n",
    "audio_metrics = compute_audio_network_metrics(AUDIO_PATH)\n",
    "\n",
    "# Build a small DataFrame for scalar metrics\n",
    "compare_keys = [\n",
    "    \"n_nodes\",\n",
    "    \"n_edges\",\n",
    "    \"density\",\n",
    "    \"r_real\",\n",
    "    \"r_null\",\n",
    "    \"rho_norm\",\n",
    "    \"mean_entropy\",\n",
    "    \"eff_unweighted\",\n",
    "    \"eff_weighted\",\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for domain, metrics in [(\"MIDI\", midi_metrics), (\"Audio\", audio_metrics)]:\n",
    "    row = {\"domain\": domain}\n",
    "    for k in compare_keys:\n",
    "        row[k] = metrics[k]\n",
    "    rows.append(row)\n",
    "\n",
    "df_compare = pd.DataFrame(rows).set_index(\"domain\")\n",
    "df_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42167eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "iv_midi = midi_metrics[\"interval_vec\"]\n",
    "iv_audio = audio_metrics[\"interval_vec\"]\n",
    "\n",
    "cosine_sim = float(np.dot(iv_midi, iv_audio) / (norm(iv_midi) * norm(iv_audio) + EPS))\n",
    "cosine_sim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d1e85",
   "metadata": {},
   "source": [
    "Visualize interval profiles (MIDI vs Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: interval profile comparison\n",
    "\n",
    "interval_names = [\n",
    "    \"0 (unison)\",\n",
    "    \"1 (m2)\",\n",
    "    \"2 (M2)\",\n",
    "    \"3 (m3)\",\n",
    "    \"4 (M3)\",\n",
    "    \"5 (P4)\",\n",
    "    \"6 (TT)\",\n",
    "    \"7 (P5)\",\n",
    "    \"8 (m6)\",\n",
    "    \"9 (M6)\",\n",
    "    \"10 (m7)\",\n",
    "    \"11 (M7)\",\n",
    "]\n",
    "\n",
    "iv_midi = midi_metrics[\"interval_vec\"]\n",
    "iv_audio = audio_metrics[\"interval_vec\"]\n",
    "\n",
    "x = np.arange(12)\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x - width/2, iv_midi, width, label=\"MIDI\")\n",
    "plt.bar(x + width/2, iv_audio, width, label=\"Audio (chroma)\")\n",
    "\n",
    "plt.xticks(x, interval_names, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"L2-normalized weight\")\n",
    "plt.title(\"Interval profile (pitch-class transitions) – Für Elise\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6b2ac",
   "metadata": {},
   "source": [
    "visualize the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: network visualizations (optional)\n",
    "\n",
    "def plot_pitchclass_graph(G, title=\"\"):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        print(\"Empty graph\")\n",
    "        return\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=0)\n",
    "    weights = np.array([d[\"weight\"] for _, _, d in G.edges(data=True)], dtype=float)\n",
    "    if len(weights) > 0:\n",
    "        # normalize edge widths for visibility\n",
    "        w_norm = 1 + 4 * (weights - weights.min()) / (weights.max() - weights.min() + EPS)\n",
    "    else:\n",
    "        w_norm = 1.0\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=500)\n",
    "    nx.draw_networkx_labels(G, pos, labels={n: str(n) for n in G.nodes()})\n",
    "    nx.draw_networkx_edges(G, pos, width=w_norm, arrows=True, arrowstyle=\"->\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_pitchclass_graph(midi_metrics[\"graph\"], title=\"MIDI pitch-class network – Für Elise\")\n",
    "plot_pitchclass_graph(audio_metrics[\"graph\"], title=\"Audio chroma network – Für Elise\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
